name: Scrap and Update Kaggle Dataset

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'

env:
    DATASET_NAME: 'furkanzeki/bkm-book-dataset'
    FILE_NAME: 'BKM_Datasets.csv'
    GITHUB_WORKSPACE: ${{ github.workspace }}

jobs:
  scrape_categories:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.10.6

    - name: Install Python Dependencies
      run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

    - name: Categories Scrape
      run: |
          python Scripts/BKM/scrape_categories.py

    - name: Download Kaggle Dataset
      env:
        KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        DATASET_NAME: ${{ env.DATASET_NAME }}
      run: python Scripts/dataset_download.py
    
    - name: Upload dataset as artifact
      uses: actions/upload-artifact@v2
      with:
        name: bkm_dataset
        path: data/
        retention-days: 1

    - name: Upload categories artifact
      uses: actions/upload-artifact@v2
      with:
        name: bkm_categories
        path: |
            categories_1.json
            categories_2.json
            categories_3.json
            categories_4.json
            categories_5.json
        retention-days: 1

  scrape_job:
    needs: scrape_categories
    runs-on: ubuntu-latest
    strategy:
      matrix:
        job_id: [1, 2, 3, 4, 5]  # Job sayısını ihtiyacınıza göre artırabilirsiniz

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.10.6

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Download bkm_dataset artifact
      uses: actions/download-artifact@v2
      with:
        name: bkm_dataset #Dataset ana dizine ekleniyor
        path: data/

    - name: Download categories artifact
      uses: actions/download-artifact@v2
      with:
        name: bkm_categories
    
    - name: Install dependencies
      run: ls

    - name: Scraping Start
      env:
        categories_file: categories_${{ matrix.job_id }}.json
        matrix_id: ${{ matrix.job_id }}
      run: |
        python Scripts/BKM/scrape.py

    - name: Upload artifact
      uses: actions/upload-artifact@v2
      with:
        name: scraping data
        path: Dataset/BKM__${{ matrix.job_id }}.csv

  combine:
    runs-on: ubuntu-latest
    needs: scrape_job
    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.10.6

    - name: Install dependencies
      run: |
        pip install pandas kaggle

    - name: Download artifacts
      uses: actions/download-artifact@v2
      with:
        name: books_*
        path: .

    - name: Combine datasets
      run: |
        python combine.py
      env:
        KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}

    - name: Cleanup artifacts
      run: |
        rm books_*.csv
